{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OussamaHaff/machine-learning-upskilling/blob/main/02-llms-from-scratch/04-token-embeddings-with-positional-encoding/token_embeddings_with_positisional_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic token IDs to embedding vectors"
      ],
      "metadata": {
        "id": "initial_id"
      },
      "id": "initial_id"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploration"
      ],
      "metadata": {
        "id": "-jm1a3hezyBS"
      },
      "id": "-jm1a3hezyBS"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "input_token_ids = torch.tensor([2, 3, 5, 1])\n",
        "\n",
        "vocab_size = 6\n",
        "output_embeddings_dim_size = 3\n",
        "\n",
        "# Instantiate an embedding layer (with random seed 123 for reproducibility)\n",
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size,\n",
        "    embedding_dim=output_embeddings_dim_size)\n",
        "print(\"Wights \\n\", embedding_layer.weight)\n",
        "print(\"Shape\\n\", embedding_layer.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn8r1m8XOvti",
        "outputId": "49c72373-3b85-4db0-9389-9a5984207ec3"
      },
      "id": "Cn8r1m8XOvti",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wights \n",
            " Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n",
            "Shape\n",
            " torch.Size([6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor([3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9fW0JReTt1V",
        "outputId": "5a0f9b03-d236-42db-fd90-dc9f5acc2be3"
      },
      "id": "y9fW0JReTt1V",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(input_token_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2OD-ApRVMPn",
        "outputId": "ba1ad2ab-7945-44ee-f42b-98c1ea4cabf0"
      },
      "id": "K2OD-ApRVMPn",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observations\n",
        "\n",
        "- Initial Embedding weights are random.\n",
        "- The Embedding layer is essentially a lookup function to get wights of of token IDs."
      ],
      "metadata": {
        "id": "hzvmZOaccKiD"
      },
      "id": "hzvmZOaccKiD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mini positional embedding"
      ],
      "metadata": {
        "id": "-CTsrkLZiibW"
      },
      "id": "-CTsrkLZiibW"
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "pos_embedding_layer = torch.nn.Embedding(\n",
        "    num_embeddings=max_length, embedding_dim=output_embeddings_dim_size)\n",
        "\n",
        "positions = torch.arange(max_length)\n",
        "\n",
        "pos_embeddings = pos_embedding_layer(positions)\n",
        "\n",
        "mini_embedding = embedding_layer(input_token_ids)\n",
        "\n",
        "mini_input_embeddings = mini_embedding + pos_embeddings\n",
        "\n",
        "print(\"Embeddings\")\n",
        "print(mini_embedding)\n",
        "print(\"Positions\")\n",
        "print(positions)\n",
        "print(\"Positional Embeddings\")\n",
        "print(pos_embeddings)\n",
        "print(\"Target Embeddings\")\n",
        "print(mini_input_embeddings)"
      ],
      "metadata": {
        "id": "_ADvKAfjV7tG",
        "outputId": "d2435948-69fd-41ad-c96b-23caf0eff84c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_ADvKAfjV7tG",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings\n",
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n",
            "Positions\n",
            "tensor([0, 1, 2, 3])\n",
            "Positional Embeddings\n",
            "tensor([[ 1.1621,  0.0253,  0.5817],\n",
            "        [-0.5675, -0.8296, -0.9905],\n",
            "        [ 0.0182,  0.6924, -1.5154],\n",
            "        [ 0.5716,  0.5938, -0.9716]], grad_fn=<EmbeddingBackward0>)\n",
            "Target Embeddings\n",
            "tensor([[ 2.4374, -0.1756,  0.4211],\n",
            "        [-0.9690,  0.1370, -2.1387],\n",
            "        [-2.8218, -0.0924, -2.9250],\n",
            "        [ 1.4894,  2.1748,  0.3294]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QCb0Ko2RabQJ"
      },
      "id": "QCb0Ko2RabQJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding with positional encoding"
      ],
      "metadata": {
        "id": "YVSz2e9v1lcF"
      },
      "id": "YVSz2e9v1lcF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From previous step"
      ],
      "metadata": {
        "id": "tgg9AxJs5VR_"
      },
      "id": "tgg9AxJs5VR_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Collab\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "p26LHg_j7m1B",
        "outputId": "6918e9ea-7e03-401d-89ac-1af4f79d26bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p26LHg_j7m1B",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  \"\"\"Contructs a PyTorch Dataset with \"\"\"\n",
        "  def __init__(self, text, tokeniser, sliding_window_max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    tokenised_text = tokeniser.encode(text)\n",
        "\n",
        "    for i in range(0, len(tokenised_text) - sliding_window_max_length, stride):\n",
        "      input_chunk = tokenised_text[i: i + sliding_window_max_length]\n",
        "      target_chunk = tokenised_text[i + 1 : i + sliding_window_max_length + 1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, id):\n",
        "    return self.input_ids[id], self.target_ids[id]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(text, batch_size=4, sliding_window_max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "  tokeniser = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(text, tokeniser, sliding_window_max_length, stride)\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      drop_last=drop_last,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "  return dataloader\n",
        "\n",
        "\n",
        "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as dataset_file:\n",
        "  raw_text = dataset_file.read()"
      ],
      "metadata": {
        "id": "tfLG43_X5Yok"
      },
      "id": "tfLG43_X5Yok",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dimension = 256\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=output_dimension)\n",
        "print(token_embedding_layer.weight.shape)"
      ],
      "metadata": {
        "id": "YJnXDa1-1rnY",
        "outputId": "92f889b5-416d-46f3-fbdd-b5af853bdd9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YJnXDa1-1rnY",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50257, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, sliding_window_max_length=max_length,\n",
        "    stride=max_length, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "\n",
        "print(\"Token IDs:\\n\", inputs)\n",
        "print(\"Input shape:\\n\", inputs.shape)\n"
      ],
      "metadata": {
        "id": "zxsFYjjE6Dc-",
        "outputId": "66dc0a0b-fdbb-4448-c4f6-0f892711316a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zxsFYjjE6Dc-",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "Input shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_embeddings = token_embedding_layer(inputs)\n",
        "\n",
        "print(tokens_embeddings.shape)"
      ],
      "metadata": {
        "id": "Mtz5A2BR8qRa",
        "outputId": "23813f1c-9b75-4b01-841b-2306b270527e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Mtz5A2BR8qRa",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "positional_embedding_layer = torch.nn.Embedding(\n",
        "    num_embeddings=context_length, embedding_dim=output_dimension)\n",
        "positional_embeddings = positional_embedding_layer(torch.arange(context_length))\n",
        "\n",
        "print(positional_embeddings.shape)\n"
      ],
      "metadata": {
        "id": "LRhg_bdbAtjP",
        "outputId": "839c5aae-5af1-4988-f892-914c98f6a74e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LRhg_bdbAtjP",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = tokens_embedding + positional_embeddings\n",
        "print(input_embeddings)"
      ],
      "metadata": {
        "id": "lOHMqzmhS9G3",
        "outputId": "b0505322-b554-4e19-cede-faac7295371b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lOHMqzmhS9G3",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.1555, -0.3882, -0.6872,  ...,  0.3243,  3.4303, -0.8312],\n",
            "         [-1.6216, -0.2573, -1.7572,  ..., -0.4452, -2.4622,  0.1155],\n",
            "         [-0.9715,  1.4540,  0.4088,  ...,  0.9573,  2.0514, -0.2320],\n",
            "         [-0.8488,  1.1452,  0.1831,  ...,  0.5796,  2.0372, -1.4826]],\n",
            "\n",
            "        [[ 2.2112,  1.1132, -0.3223,  ...,  0.4431,  2.2109, -0.1119],\n",
            "         [-1.0261, -1.0020, -0.6953,  ..., -1.5052, -1.7355,  0.9296],\n",
            "         [-0.5452,  0.0628,  0.2625,  ...,  0.8108, -0.0856, -0.0732],\n",
            "         [-0.8441,  2.7050,  0.8911,  ..., -0.2137,  0.2933, -0.0098]],\n",
            "\n",
            "        [[ 1.6476, -0.5286, -1.2389,  ...,  1.1974,  0.8194, -2.0030],\n",
            "         [-0.5285, -0.5203, -0.9484,  ..., -0.4651, -3.3541,  0.7916],\n",
            "         [ 1.2956,  1.6018,  0.3258,  ..., -0.7885,  0.7958, -1.1924],\n",
            "         [-0.2042,  0.5778,  0.8281,  ...,  1.5140, -0.1738, -0.4808]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.0647,  1.1278,  0.1049,  ...,  1.1730,  0.0323,  1.2470],\n",
            "         [-2.0486, -0.8185, -2.0130,  ..., -1.6087, -1.7726,  0.5504],\n",
            "         [ 1.3389,  3.2366, -0.7783,  ..., -0.1106,  3.5684,  0.8600],\n",
            "         [ 1.3936,  2.0981,  0.9718,  ...,  2.2244,  0.5847, -1.2002]],\n",
            "\n",
            "        [[ 1.0745, -0.6855, -0.8444,  ...,  1.0193,  0.9422, -0.0974],\n",
            "         [ 0.5699, -1.2959, -2.3496,  ..., -0.4201, -2.5775,  1.5432],\n",
            "         [ 0.0855,  2.1239,  1.1368,  ...,  0.2527,  2.3184, -0.2382],\n",
            "         [ 0.2343,  0.9874,  2.7702,  ...,  0.1922, -0.8367,  0.9216]],\n",
            "\n",
            "        [[ 1.3249,  0.7702,  0.1274,  ...,  1.3063,  1.7014, -0.2172],\n",
            "         [ 0.7387, -0.2599, -2.9758,  ..., -1.4970, -5.1242,  1.0384],\n",
            "         [-2.3051,  3.0360, -0.3754,  ..., -0.7208,  2.8241,  1.3925],\n",
            "         [ 0.6300,  2.1514,  2.9105,  ...,  0.4657, -1.2754, -1.8186]]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quz2p_ZZVBmC"
      },
      "id": "quz2p_ZZVBmC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}