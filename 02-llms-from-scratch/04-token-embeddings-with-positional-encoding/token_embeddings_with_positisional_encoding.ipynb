{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/OussamaHaff/machine-learning-upskilling/blob/main/02-llms-from-scratch/04-token-embeddings-with-positional-encoding/token_embeddings_with_positisional_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "825837dd865aa432"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Basic token IDs to embedding vectors"
   ],
   "metadata": {
    "id": "initial_id"
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploration"
   ],
   "metadata": {
    "id": "-jm1a3hezyBS"
   },
   "id": "-jm1a3hezyBS"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "input_token_ids = torch.tensor([2, 3, 5, 1])\n",
    "\n",
    "vocab_size = 6\n",
    "output_embeddings_dim_size = 3\n",
    "\n",
    "# Instantiate an embedding layer (with random seed 123 for reproducibility)\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size,\n",
    "    embedding_dim=output_embeddings_dim_size)\n",
    "print(\"Wights \\n\", embedding_layer.weight)\n",
    "print(\"Shape\\n\", embedding_layer.weight.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cn8r1m8XOvti",
    "outputId": "49c72373-3b85-4db0-9389-9a5984207ec3",
    "ExecuteTime": {
     "end_time": "2025-02-17T06:37:08.367338Z",
     "start_time": "2025-02-17T06:37:08.355588Z"
    }
   },
   "id": "Cn8r1m8XOvti",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wights \n",
      " Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n",
      "Shape\n",
      " torch.Size([6, 3])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9fW0JReTt1V",
    "outputId": "5a0f9b03-d236-42db-fd90-dc9f5acc2be3",
    "ExecuteTime": {
     "end_time": "2025-02-17T06:37:11.333682Z",
     "start_time": "2025-02-17T06:37:11.330125Z"
    }
   },
   "id": "y9fW0JReTt1V",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "print(embedding_layer(input_token_ids))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2OD-ApRVMPn",
    "outputId": "ba1ad2ab-7945-44ee-f42b-98c1ea4cabf0",
    "ExecuteTime": {
     "end_time": "2025-02-17T06:37:13.586833Z",
     "start_time": "2025-02-17T06:37:13.583742Z"
    }
   },
   "id": "K2OD-ApRVMPn",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Observations\n",
    "\n",
    "- Initial Embedding weights are random.\n",
    "- The Embedding layer is essentially a lookup function to get wights of of token IDs."
   ],
   "metadata": {
    "id": "hzvmZOaccKiD"
   },
   "id": "hzvmZOaccKiD"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mini positional embedding"
   ],
   "metadata": {
    "id": "-CTsrkLZiibW"
   },
   "id": "-CTsrkLZiibW"
  },
  {
   "cell_type": "code",
   "source": [
    "max_length = 4\n",
    "pos_embedding_layer = torch.nn.Embedding(\n",
    "    num_embeddings=max_length, embedding_dim=output_embeddings_dim_size)\n",
    "\n",
    "positions = torch.arange(max_length)\n",
    "\n",
    "pos_embeddings = pos_embedding_layer(positions)\n",
    "\n",
    "mini_embedding = embedding_layer(input_token_ids)\n",
    "\n",
    "mini_input_embeddings = mini_embedding + pos_embeddings\n",
    "\n",
    "print(\"Embeddings\")\n",
    "print(mini_embedding)\n",
    "print(\"Positions\")\n",
    "print(positions)\n",
    "print(\"Positional Embeddings\")\n",
    "print(pos_embeddings)\n",
    "print(\"Target Embeddings\")\n",
    "print(mini_input_embeddings)"
   ],
   "metadata": {
    "id": "_ADvKAfjV7tG",
    "outputId": "d2435948-69fd-41ad-c96b-23caf0eff84c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-02-17T06:37:47.428119Z",
     "start_time": "2025-02-17T06:37:47.423733Z"
    }
   },
   "id": "_ADvKAfjV7tG",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings\n",
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n",
      "Positions\n",
      "tensor([0, 1, 2, 3])\n",
      "Positional Embeddings\n",
      "tensor([[-0.6307,  1.2340,  0.3127],\n",
      "        [ 0.6972, -0.9950, -1.1476],\n",
      "        [-0.9178,  0.9045, -2.0975],\n",
      "        [ 1.1558, -1.2157,  0.1295]], grad_fn=<EmbeddingBackward0>)\n",
      "Target Embeddings\n",
      "tensor([[ 0.6446,  1.0331,  0.1521],\n",
      "        [ 0.2957, -0.0285, -2.2958],\n",
      "        [-3.7578,  0.1197, -3.5071],\n",
      "        [ 2.0735,  0.3653,  1.4306]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "QCb0Ko2RabQJ"
   },
   "id": "QCb0Ko2RabQJ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embedding with positional encoding"
   ],
   "metadata": {
    "id": "YVSz2e9v1lcF"
   },
   "id": "YVSz2e9v1lcF"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## From previous step"
   ],
   "metadata": {
    "id": "tgg9AxJs5VR_"
   },
   "id": "tgg9AxJs5VR_"
  },
  {
   "cell_type": "code",
   "source": [
    "# Google Collab\n",
    "!pip install tiktoken"
   ],
   "metadata": {
    "id": "p26LHg_j7m1B",
    "outputId": "6918e9ea-7e03-401d-89ac-1af4f79d26bb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "p26LHg_j7m1B",
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m12.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "  \"\"\"Contructs a PyTorch Dataset with \"\"\"\n",
    "  def __init__(self, text, tokeniser, sliding_window_max_length, stride):\n",
    "    self.input_ids = []\n",
    "    self.target_ids = []\n",
    "\n",
    "    tokenised_text = tokeniser.encode(text)\n",
    "\n",
    "    for i in range(0, len(tokenised_text) - sliding_window_max_length, stride):\n",
    "      input_chunk = tokenised_text[i: i + sliding_window_max_length]\n",
    "      target_chunk = tokenised_text[i + 1 : i + sliding_window_max_length + 1]\n",
    "      self.input_ids.append(torch.tensor(input_chunk))\n",
    "      self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "\n",
    "  def __getitem__(self, id):\n",
    "    return self.input_ids[id], self.target_ids[id]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(text, batch_size=4, sliding_window_max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "  tokeniser = tiktoken.get_encoding(\"gpt2\")\n",
    "  dataset = GPTDatasetV1(text, tokeniser, sliding_window_max_length, stride)\n",
    "  dataloader = DataLoader(\n",
    "      dataset,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=shuffle,\n",
    "      drop_last=drop_last,\n",
    "      num_workers=num_workers\n",
    "  )\n",
    "  return dataloader\n",
    "\n",
    "\n",
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as dataset_file:\n",
    "  raw_text = dataset_file.read()"
   ],
   "metadata": {
    "id": "tfLG43_X5Yok",
    "ExecuteTime": {
     "end_time": "2025-02-17T06:37:55.132780Z",
     "start_time": "2025-02-17T06:37:55.117358Z"
    }
   },
   "id": "tfLG43_X5Yok",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "vocab_size = 50257\n",
    "output_dimension = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=output_dimension)\n",
    "print(token_embedding_layer.weight.shape)"
   ],
   "metadata": {
    "id": "YJnXDa1-1rnY",
    "outputId": "92f889b5-416d-46f3-fbdd-b5af853bdd9a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-02-17T06:37:59.381180Z",
     "start_time": "2025-02-17T06:37:59.265934Z"
    }
   },
   "id": "YJnXDa1-1rnY",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 256])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, sliding_window_max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"Input shape:\\n\", inputs.shape)\n"
   ],
   "metadata": {
    "id": "zxsFYjjE6Dc-",
    "outputId": "66dc0a0b-fdbb-4448-c4f6-0f892711316a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-02-17T06:38:03.344534Z",
     "start_time": "2025-02-17T06:38:03.191007Z"
    }
   },
   "id": "zxsFYjjE6Dc-",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "Input shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "tokens_embeddings = token_embedding_layer(inputs)\n",
    "\n",
    "print(tokens_embeddings.shape)"
   ],
   "metadata": {
    "id": "Mtz5A2BR8qRa",
    "outputId": "23813f1c-9b75-4b01-841b-2306b270527e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-02-17T06:38:08.054772Z",
     "start_time": "2025-02-17T06:38:08.052264Z"
    }
   },
   "id": "Mtz5A2BR8qRa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "context_length = max_length\n",
    "positional_embedding_layer = torch.nn.Embedding(\n",
    "    num_embeddings=context_length, embedding_dim=output_dimension)\n",
    "positional_embeddings = positional_embedding_layer(torch.arange(context_length))\n",
    "\n",
    "print(positional_embeddings.shape)\n"
   ],
   "metadata": {
    "id": "LRhg_bdbAtjP",
    "outputId": "839c5aae-5af1-4988-f892-914c98f6a74e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-02-17T06:38:12.380632Z",
     "start_time": "2025-02-17T06:38:12.377907Z"
    }
   },
   "id": "LRhg_bdbAtjP",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "input_embeddings = tokens_embeddings + positional_embeddings\n",
    "print(input_embeddings)"
   ],
   "metadata": {
    "id": "lOHMqzmhS9G3",
    "outputId": "b0505322-b554-4e19-cede-faac7295371b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-02-17T06:38:51.416908Z",
     "start_time": "2025-02-17T06:38:51.412544Z"
    }
   },
   "id": "lOHMqzmhS9G3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.9733e+00, -1.1072e+00, -5.2032e-01,  ...,  8.7353e-01,\n",
      "           4.6812e-01, -1.8006e+00],\n",
      "         [ 9.4603e-01,  9.4199e-01,  1.4485e+00,  ...,  1.1931e+00,\n",
      "           1.3748e+00,  3.0240e-01],\n",
      "         [ 8.5075e-02, -2.6711e+00,  4.6235e-01,  ...,  7.9787e-01,\n",
      "          -9.1028e-01, -1.8978e+00],\n",
      "         [-7.2105e-01,  2.7123e+00,  9.3291e-01,  ...,  5.8263e-01,\n",
      "          -3.6140e-01, -3.3350e-01]],\n",
      "\n",
      "        [[-3.0873e+00, -7.2548e-01, -1.7576e+00,  ...,  6.8093e-02,\n",
      "          -2.1905e+00,  1.1768e-01],\n",
      "         [ 4.9539e-01, -3.5410e-01,  3.1399e-01,  ...,  5.4345e-02,\n",
      "           4.2503e-01, -1.9022e+00],\n",
      "         [ 1.1498e+00, -9.0849e-01,  7.0826e-01,  ...,  6.9908e-01,\n",
      "           4.1368e-01, -1.4251e+00],\n",
      "         [-2.9778e-01, -9.2440e-02, -1.9248e-01,  ...,  2.0688e+00,\n",
      "          -4.6172e-01,  1.7991e+00]],\n",
      "\n",
      "        [[-3.2814e+00, -1.1842e+00, -1.4793e+00,  ..., -3.6210e-01,\n",
      "          -1.6815e+00, -1.0105e+00],\n",
      "         [ 9.8176e-01,  1.2346e+00,  2.8820e+00,  ...,  9.7957e-01,\n",
      "           2.7285e-01,  5.6322e-03],\n",
      "         [ 1.7723e+00, -2.4719e+00,  1.7604e+00,  ...,  1.0403e+00,\n",
      "          -7.5550e-01, -2.2673e+00],\n",
      "         [-2.8186e-01,  2.3759e+00,  7.8811e-01,  ..., -8.5207e-01,\n",
      "          -4.5544e-01,  1.1007e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.4414e+00,  4.6541e-01, -1.1333e+00,  ..., -1.9328e-01,\n",
      "          -2.1174e+00, -7.2658e-01],\n",
      "         [ 1.1027e+00, -2.3373e-01, -6.1585e-01,  ...,  7.1709e-02,\n",
      "           4.4744e-01, -7.1985e-01],\n",
      "         [ 8.0324e-02, -2.8227e+00, -1.7776e-01,  ...,  9.1956e-01,\n",
      "           5.1403e-01, -2.3796e+00],\n",
      "         [ 1.2778e+00, -7.5969e-01,  1.4877e+00,  ..., -6.1142e-01,\n",
      "          -1.8060e+00, -4.5772e-01]],\n",
      "\n",
      "        [[-2.1944e+00, -1.8324e-01, -3.4582e-01,  ..., -2.8561e-01,\n",
      "          -1.4161e+00,  2.1543e-01],\n",
      "         [ 1.8091e+00,  9.6077e-01, -1.1105e+00,  ...,  3.9497e-01,\n",
      "           1.0566e+00, -2.9111e-01],\n",
      "         [ 2.4882e+00,  3.9876e-01,  6.7839e-01,  ...,  8.7823e-01,\n",
      "          -1.3445e-01, -2.4683e+00],\n",
      "         [ 4.6535e-01,  3.3916e-01,  1.2715e+00,  ...,  8.7429e-01,\n",
      "          -1.6195e-03, -6.7553e-01]],\n",
      "\n",
      "        [[-5.4518e-01,  1.5436e+00, -8.2337e-01,  ...,  6.0218e-02,\n",
      "          -1.1936e+00, -1.9608e+00],\n",
      "         [-6.5478e-01,  2.0329e+00,  5.7578e-01,  ..., -8.6486e-03,\n",
      "           1.7072e+00, -1.5107e+00],\n",
      "         [ 8.9034e-01, -1.9203e+00,  1.3656e+00,  ...,  1.3330e+00,\n",
      "          -2.5851e-01, -2.6890e+00],\n",
      "         [ 4.5252e-01,  1.5656e+00, -5.2263e-01,  ...,  2.0061e+00,\n",
      "          -1.2187e+00, -1.8847e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The following illustration describes my understanding of the process of preparing data for training from tokenisation to positional embeddings.\n",
    "\n",
    "![Understanding of tokenisation to positional embeddings](resources/tokenisation-to-positional-embeddings.png)\n",
    "\n"
   ],
   "id": "1fa08dde7424600f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
