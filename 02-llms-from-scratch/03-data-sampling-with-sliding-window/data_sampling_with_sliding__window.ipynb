{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/OussamaHaff/machine-learning-upskilling/blob/main/02-llms-from-scratch/03-data-sampling-with-sliding-window/data_sampling_with_sliding__window.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "b3c5f67abe788e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Table of Contents\n",
    "- [Basic input-target pairs generation](#basic-input-target-pairs-generation)\n",
    "- [Create the input-target pairs](#create-the-input-target-pairs)\n",
    "  - [Using Vanilla Python](#using-vanilla-python)\n",
    "  - [Using PyTorch's Tensors & DataLoader](#using-pytorchs-tensors--dataloader)\n"
   ],
   "id": "b420b75041a8fba9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Basic input-target pairs generation"
   ],
   "metadata": {
    "id": "cfDSHudj8wV1"
   },
   "id": "cfDSHudj8wV1"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install tiktoken\n",
    "import tiktoken\n",
    "\n",
    "tokeniser = tiktoken.get_encoding(\"gpt2\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2ryKmKs24D6",
    "outputId": "cba8824c-056f-4804-edff-a74201d97024",
    "ExecuteTime": {
     "end_time": "2025-02-15T19:15:59.556241Z",
     "start_time": "2025-02-15T19:15:59.103916Z"
    }
   },
   "id": "m2ryKmKs24D6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-15T13:40:39.006428Z",
     "start_time": "2025-02-15T13:40:39.001369Z"
    },
    "id": "initial_id"
   },
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as data_file:\n",
    "  raw_text = data_file.read()\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "encoded_text = tokeniser.encode(raw_text)\n",
    "print(len(encoded_text))\n",
    "print(encoded_text[:52])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNAdmI7_3VLQ",
    "outputId": "662fd21e-c990-448c-c2d5-c18ec8dc1399"
   },
   "id": "LNAdmI7_3VLQ",
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5145\n",
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257, 7026, 15632, 438, 2016, 257, 922, 5891, 1576, 438, 568, 340, 373, 645, 1049, 5975, 284, 502, 284, 3285, 326, 11, 287, 262, 6001, 286, 465, 13476, 11, 339, 550, 5710, 465, 12036, 11, 6405, 257, 5527, 27075, 11, 290, 4920]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove first 50 elements\n",
    "\n",
    "encoded_sample = encoded_text[50:]\n",
    "print(encoded_sample[:10])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sbbRXMHE39TZ",
    "outputId": "9fec6b2a-21bb-4394-c894-236aa31d3224"
   },
   "id": "sbbRXMHE39TZ",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[290, 4920, 2241, 287, 257, 4489, 64, 319, 262, 34686]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the input-target pairs\n",
    "## Using Vanilla Python"
   ],
   "metadata": {
    "id": "upFPy0kL41WS"
   },
   "id": "upFPy0kL41WS"
  },
  {
   "cell_type": "code",
   "source": [
    "context_size = 4\n",
    "input_x = encoded_sample[:context_size]\n",
    "target_y = encoded_sample[1:context_size+1]\n",
    "\n",
    "print(input_x)\n",
    "print(f\"     {target_y}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxtDF4bx4_jZ",
    "outputId": "d23f9792-b27e-46be-b44b-6eba61c549b7"
   },
   "id": "YxtDF4bx4_jZ",
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[290, 4920, 2241, 287]\n",
      "     [4920, 2241, 287, 257]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(1, context_size+1):\n",
    "  context = encoded_sample[:i]\n",
    "  desired = encoded_sample[i]\n",
    "  print(context, \"----->\", desired)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUZri33x63M4",
    "outputId": "f54189e4-202a-448e-cd71-b1d76928cb63"
   },
   "id": "jUZri33x63M4",
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[290] -----> 4920\n",
      "[290, 4920] -----> 2241\n",
      "[290, 4920, 2241] -----> 287\n",
      "[290, 4920, 2241, 287] -----> 257\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(1, context_size+1):\n",
    "  context = encoded_sample[:i]\n",
    "  desired = encoded_sample[i]\n",
    "  print(tokeniser.decode(context), \"----->\", tokeniser.decode([desired]))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "peD-QFCS8RwP",
    "outputId": "430888af-7262-42e0-e0f6-f0a96336de17"
   },
   "id": "peD-QFCS8RwP",
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " and ----->  established\n",
      " and established ----->  himself\n",
      " and established himself ----->  in\n",
      " and established himself in ----->  a\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Using PyTorch's Tensors & DataLoader",
   "metadata": {
    "id": "zBDGFFV8v77j"
   },
   "id": "zBDGFFV8v77j"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "  \"\"\"Contructs a PyTorch Dataset with \"\"\"\n",
    "  def __init__(self, text, tokeniser, sliding_window_max_length, stride):\n",
    "    self.input_ids = []\n",
    "    self.target_ids = []\n",
    "\n",
    "    tokenised_text = tokeniser.encode(text)\n",
    "\n",
    "    for i in range(0, len(tokenised_text) - sliding_window_max_length, stride):\n",
    "      input_chunk = tokenised_text[i: i + sliding_window_max_length]\n",
    "      target_chunk = tokenised_text[i + 1 : i + sliding_window_max_length + 1]\n",
    "      self.input_ids.append(torch.tensor(input_chunk))\n",
    "      self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "\n",
    "  def __getitem__(self, id):\n",
    "    return self.input_ids[id], self.target_ids[id]"
   ],
   "metadata": {
    "id": "Z7O2xgrEweQi",
    "ExecuteTime": {
     "end_time": "2025-02-15T19:15:36.630977Z",
     "start_time": "2025-02-15T19:15:33.545052Z"
    }
   },
   "id": "Z7O2xgrEweQi",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oussama.hafferssas/projects/personal/machine-learning-upskilling/02-llms-from-scratch/03-data-sampling-with-sliding-window/.venv/lib/python3.9/site-packages/torch/_subclasses/functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "def create_dataloader_v1(text, batch_size=4, sliding_window_max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "  tokeniser = tiktoken.get_encoding(\"gpt2\")\n",
    "  dataset = GPTDatasetV1(text, tokeniser, sliding_window_max_length, stride)\n",
    "  dataloader = DataLoader(\n",
    "      dataset,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=shuffle,\n",
    "      drop_last=drop_last,\n",
    "      num_workers=num_workers\n",
    "  )\n",
    "  return dataloader"
   ],
   "metadata": {
    "id": "QxlQ1WQpzFnQ",
    "ExecuteTime": {
     "end_time": "2025-02-15T19:15:43.920141Z",
     "start_time": "2025-02-15T19:15:43.917048Z"
    }
   },
   "id": "QxlQ1WQpzFnQ",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as dataset_file:\n",
    "  raw_text = dataset_file.read()\n",
    "\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, sliding_window_max_length=4, stride=2, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)\n",
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ],
   "metadata": {
    "id": "mitSor0M1oVu",
    "outputId": "42c5d20f-b2a6-4be3-9969-2ae6d45cfb02",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-02-15T19:16:03.303159Z",
     "start_time": "2025-02-15T19:16:03.278375Z"
    }
   },
   "id": "mitSor0M1oVu",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n",
      "[tensor([[2885, 1464, 1807, 3619]]), tensor([[1464, 1807, 3619,  402]])]\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
